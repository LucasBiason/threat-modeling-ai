# Threat Modeling AI - Environment Variables
# Copy to configs/.env and fill in values

# API Settings
APP_NAME=Threat Modeling AI
APP_VERSION=1.0.0
DEBUG=false
LOG_LEVEL=INFO
ENVIRONMENT=development
SYSTEM_VERSION=1.0.0

# CORS Settings (comma-separated for multiple origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:80
CORS_ALLOW_CREDENTIALS=true

# LLM Provider API Keys
GOOGLE_API_KEY=
OPENAI_API_KEY=

# Ollama Settings (local fallback)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2-vl

# Model Settings
PRIMARY_MODEL=gemini-1.5-pro
FALLBACK_MODEL=gpt-4o
FAST_MODEL=gemini-1.5-flash
EMBEDDING_MODEL=models/embedding-001
LLM_TEMPERATURE=0.0

# RAG Settings (caminho para docs/knowledge-base com arquivos .md STRIDE/DREAD)
# Local: caminho absoluto ou relativo ao projeto. Docker: use /kb (volume montado)
KNOWLEDGE_BASE_PATH=/kb
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=80

# File Upload Settings
MAX_UPLOAD_SIZE_MB=10

# Pipeline
# DummyPipeline só para testes unitários; false = usa LLM (Diagram, STRIDE, DREAD)
USE_DUMMY_PIPELINE=false
